{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a csv file with labels and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:06<00:00,  4.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# get all the directory paths\n",
    "dir_paths = os.listdir('ASL\\\\input\\\\asl_alphabet_train\\\\asl_alphabet_train')\n",
    "dir_paths.sort()\n",
    "root_path = 'ASL\\\\input\\\\asl_alphabet_train\\\\asl_alphabet_train'\n",
    "\n",
    "# Add these parameters at the top\n",
    "train_samples_per_class = 10   # 70% of total\n",
    "val_samples_per_class = 100     # 15% of total\n",
    "test_samples_per_class = 100    # 15% of total\n",
    "\n",
    "# Modify the sampling logic\n",
    "for idx, dir_path in tqdm(enumerate(dir_paths), total=len(dir_paths)):\n",
    "    all_images = os.listdir(f\"{root_path}/{dir_path}\")\n",
    "    random.shuffle(all_images)  # Shuffle the images first\n",
    "    \n",
    "    # Ensure we have enough images\n",
    "    total_samples = train_samples_per_class + val_samples_per_class + test_samples_per_class\n",
    "    if len(all_images) < total_samples:\n",
    "        raise ValueError(f\"Not enough images in {dir_path}. Need {total_samples}, have {len(all_images)}\")\n",
    "    \n",
    "    # Randomly sample images for each dataset\n",
    "    train_images = random.sample(all_images, train_samples_per_class)\n",
    "    remaining_images = list(set(all_images) - set(train_images))\n",
    "\n",
    "    val_images = random.sample(remaining_images, val_samples_per_class)\n",
    "    test_images = random.sample(list(set(remaining_images) - set(val_images)), test_samples_per_class)\n",
    "    \n",
    "    # Process and save images for each dataset\n",
    "    for dataset, images in zip(['train', 'val', 'test'], [train_images, val_images, test_images]):\n",
    "        os.makedirs(f\"ASL/input/preprocessed_image/{dataset}/{dir_path}\", exist_ok=True)\n",
    "        for image_name in images:\n",
    "            image = cv2.imread(f\"{root_path}/{dir_path}/{image_name}\")\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            cv2.imwrite(f\"ASL/input/preprocessed_image/{dataset}/{dir_path}/{image_name}\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [00:00<00:00, 4697.94it/s]\n",
      "100%|██████████| 2900/2900 [00:00<00:00, 3895.30it/s]\n",
      "100%|██████████| 2900/2900 [00:00<00:00, 3850.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data sample:\n",
      "                                       image_path  target\n",
      "0  ASL\\input\\preprocessed_image\\train\\A\\A1038.jpg     0.0\n",
      "1  ASL\\input\\preprocessed_image\\train\\A\\A1183.jpg     0.0\n",
      "2  ASL\\input\\preprocessed_image\\train\\A\\A1562.jpg     0.0\n",
      "3  ASL\\input\\preprocessed_image\\train\\A\\A1584.jpg     0.0\n",
      "4  ASL\\input\\preprocessed_image\\train\\A\\A1897.jpg     0.0\n",
      "\n",
      "Validation data sample:\n",
      "                                     image_path  target\n",
      "0    ASL\\input\\preprocessed_image\\val\\A\\A10.jpg     0.0\n",
      "1  ASL\\input\\preprocessed_image\\val\\A\\A1105.jpg     0.0\n",
      "2  ASL\\input\\preprocessed_image\\val\\A\\A1122.jpg     0.0\n",
      "3  ASL\\input\\preprocessed_image\\val\\A\\A1149.jpg     0.0\n",
      "4  ASL\\input\\preprocessed_image\\val\\A\\A1157.jpg     0.0\n",
      "\n",
      "Test data sample:\n",
      "                                      image_path  target\n",
      "0  ASL\\input\\preprocessed_image\\test\\A\\A1012.jpg     0.0\n",
      "1  ASL\\input\\preprocessed_image\\test\\A\\A1013.jpg     0.0\n",
      "2  ASL\\input\\preprocessed_image\\test\\A\\A1068.jpg     0.0\n",
      "3  ASL\\input\\preprocessed_image\\test\\A\\A1198.jpg     0.0\n",
      "4  ASL\\input\\preprocessed_image\\test\\A\\A1217.jpg     0.0\n",
      "Train data shape: (290, 2)\n",
      "Validation data shape: (2900, 2)\n",
      "Test data shape: (2900, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from imutils import paths\n",
    "\n",
    "# Create separate DataFrames for each dataset\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "# Process each dataset separately\n",
    "for dataset in ['train', 'val', 'test']:\n",
    "    # Get image paths for the current dataset\n",
    "    image_paths = list(paths.list_images(f'ASL\\\\input\\\\preprocessed_image\\\\{dataset}'))\n",
    "    \n",
    "    labels = []\n",
    "    current_df = train_data if dataset == 'train' else val_data if dataset == 'val' else test_data\n",
    "    \n",
    "    for i, image_path in tqdm(enumerate(image_paths), total=len(image_paths)):\n",
    "        label = image_path.split(os.path.sep)[-2]\n",
    "        current_df.loc[i, 'image_path'] = image_path\n",
    "        labels.append(label)\n",
    "    \n",
    "    # One hot encode the labels\n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(labels)\n",
    "    \n",
    "    # Add targets to the dataframe\n",
    "    for i in range(len(labels)):\n",
    "        index = np.argmax(labels[i])\n",
    "        current_df.loc[i, 'target'] = int(index)\n",
    "    \n",
    "    # Shuffle and save the dataset\n",
    "    current_df = current_df.sample(frac=1).reset_index(drop=True)\n",
    "    current_df.to_csv(f'ASL/input/{dataset}_data.csv', index=False)\n",
    "    \n",
    "    # Save the binarized labels\n",
    "    if dataset == 'train':  # Save only once using the train labels\n",
    "        joblib.dump(lb, 'ASL/output/lb.pkl')\n",
    "\n",
    "# Print sample data\n",
    "print(\"Train data sample:\")\n",
    "print(train_data.head(5))\n",
    "print(\"\\nValidation data sample:\")\n",
    "print(val_data.head(5))\n",
    "print(\"\\nTest data sample:\")\n",
    "print(test_data.head(5))\n",
    "\n",
    "# Print dataset shapes\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading label binarizer...\n",
      "Computation device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import cv2\n",
    "import cnn_models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "num_epoch = 200\n",
    "\n",
    "# Seed everything\n",
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED=SEED)\n",
    "\n",
    "# Set computation device\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = \"cpu\"\n",
    "print(f\"Computation device: {device}\")\n",
    "\n",
    "# Dataset class\n",
    "class ASLImageDataset(Dataset):\n",
    "    def __init__(self, path, labels, augment=False):\n",
    "        self.X = path\n",
    "        self.y = labels\n",
    "        self.augment = augment\n",
    "        if self.augment:\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(224, 224),\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.X[i])\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image at {self.X[i]}\")\n",
    "            \n",
    "        if self.augment:\n",
    "            image = self.aug(image=np.array(image))['image']\n",
    "        else:\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            \n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        label = self.y[i]\n",
    "        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Read the data from the pre-split CSV files\n",
    "train_df = pd.read_csv('ASL/input/train_data.csv')\n",
    "val_df = pd.read_csv('ASL/input/val_data.csv')\n",
    "test_df = pd.read_csv('ASL/input/test_data.csv')\n",
    "\n",
    "# Get image paths and labels\n",
    "xtrain = train_df.image_path.values\n",
    "ytrain = train_df.target.values\n",
    "\n",
    "xval = val_df.image_path.values\n",
    "yval = val_df.target.values\n",
    "\n",
    "xtest = test_df.image_path.values\n",
    "ytest = test_df.target.values\n",
    "\n",
    "# Create datasets\n",
    "train_data = ASLImageDataset(xtrain, ytrain, augment=True)\n",
    "val_data = ASLImageDataset(xval, yval, augment=False)\n",
    "test_data = ASLImageDataset(xtest, ytest, augment=False)\n",
    "\n",
    "batch_size = 1024  # set desired batch size\n",
    "\n",
    "# Create dataloaders\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNNTrainer class with only method definitions\n",
    "class CNNTrainer:\n",
    "    def __init__(self, model, device, criterion, optimizer, patience=5):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        \n",
    "    def train_epoch(self, dataloader):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for data, target in tqdm(dataloader, desc=\"Training\"):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(data)\n",
    "            loss = self.criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_correct += (preds == target).sum().item()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(F.softmax(outputs, dim=1).cpu().detach().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            \n",
    "        train_loss = running_loss / len(dataloader.dataset)\n",
    "        train_accuracy = 100. * running_correct / len(dataloader.dataset)\n",
    "        return train_loss, train_accuracy, all_preds, all_probs, all_targets\n",
    "\n",
    "    def validate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(dataloader, desc=\"Validating\"):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, target)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                running_correct += (preds == target).sum().item()\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_probs.extend(F.softmax(outputs, dim=1).cpu().detach().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                \n",
    "        val_loss = running_loss / len(dataloader.dataset)\n",
    "        val_accuracy = 100. * running_correct / len(dataloader.dataset)\n",
    "        return val_loss, val_accuracy, all_preds, all_probs, all_targets\n",
    "    \n",
    "    def early_stopping(self, val_loss):\n",
    "        improvement = self.best_loss - val_loss\n",
    "        if improvement > 0.0001:  # Only consider it an improvement if loss decreases by more than 0.0001\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            torch.save(self.model.state_dict(), 'ASL/output/best_model.pth')\n",
    "            print(f\"Model improved by {improvement:.6f}: best model saved.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"No significant improvement for {self.patience} epochs. Early stopping triggered.\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def train(self, trainloader, valloader, num_epoch):\n",
    "        train_loss, train_accuracy = [], []\n",
    "        val_loss, val_accuracy = [], []  # Corrected line\n",
    "        start = time.time()\n",
    "        for epoch in range(num_epoch):\n",
    "            print(f\"\\nEpoch {epoch+1} of {num_epoch}\")\n",
    "            \n",
    "            # Training step\n",
    "            epoch_train_loss, epoch_train_accuracy, train_preds, train_probs, train_targets = self.train_epoch(trainloader)\n",
    "            train_loss.append(epoch_train_loss)\n",
    "            train_accuracy.append(epoch_train_accuracy)\n",
    "            \n",
    "            # Calculate training metrics\n",
    "            train_auc = roc_auc_score(train_targets, train_probs, multi_class='ovr')\n",
    "            train_f1 = f1_score(train_targets, train_preds, average='weighted')\n",
    "            \n",
    "            # Validation step\n",
    "            epoch_val_loss, epoch_val_accuracy, val_preds, val_probs, val_targets = self.validate(valloader)\n",
    "            val_loss.append(epoch_val_loss)\n",
    "            val_accuracy.append(epoch_val_accuracy)\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            val_auc = roc_auc_score(val_targets, val_probs, multi_class='ovr')\n",
    "            val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
    "            \n",
    "            # Print metrics\n",
    "            print(f\"Train - Loss: {epoch_train_loss:.4f}, Accuracy: {epoch_train_accuracy:.4f}, AUC: {train_auc:.4f}, F1: {train_f1:.4f}\")\n",
    "            print(f\"Val   - Loss: {epoch_val_loss:.4f}, Accuracy: {epoch_val_accuracy:.4f}, AUC: {val_auc:.4f}, F1: {val_f1:.4f}\")\n",
    "            \n",
    "            # Early stopping check\n",
    "            if self.early_stopping(epoch_val_loss):\n",
    "                break\n",
    "                \n",
    "        end = time.time()\n",
    "        print(f\"\\nTraining complete in {(end - start)/60:.2f} minutes\")\n",
    "        train_time = (end - start)/60\n",
    "        \n",
    "        # Load and return the best model\n",
    "        best_model = self.model\n",
    "        best_model.load_state_dict(torch.load('ASL/output/best_model.pth'))\n",
    "        return best_model, train_loss, train_accuracy, val_loss, val_accuracy, train_time\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        running_correct = 0\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_targets = []\n",
    "        total_time = 0.0\n",
    "        num_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(dataloader, desc=\"Testing\"):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                # Measure inference time\n",
    "                start_time = time.time()\n",
    "                outputs = self.model(data)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                total_time += (end_time - start_time)\n",
    "                num_samples += data.size(0)\n",
    "                \n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                running_correct += (preds == target).sum().item()\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_probs.extend(F.softmax(outputs, dim=1).cpu().detach().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = 100. * running_correct/len(dataloader.dataset)\n",
    "        test_auc = roc_auc_score(all_targets, all_probs, multi_class='ovr')\n",
    "        test_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "        fps = num_samples / total_time\n",
    "        \n",
    "        return accuracy, test_auc, test_f1, fps\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading label binarizer...\n",
      "\n",
      "Training ResNet model...\n",
      "\n",
      "Epoch 1 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.96s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:37<00:00, 12.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0123, Accuracy: 2.0690, AUC: 0.4589, F1: 0.0094\n",
      "Val   - Loss: 0.0038, Accuracy: 2.0690, AUC: 0.4979, F1: 0.0038\n",
      "Model improved by inf: best model saved.\n",
      "\n",
      "Epoch 2 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0118, Accuracy: 3.7931, AUC: 0.5154, F1: 0.0356\n",
      "Val   - Loss: 0.0037, Accuracy: 3.3793, AUC: 0.5004, F1: 0.0101\n",
      "Model improved by 0.000117: best model saved.\n",
      "\n",
      "Epoch 3 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0115, Accuracy: 7.5862, AUC: 0.5825, F1: 0.0693\n",
      "Val   - Loss: 0.0036, Accuracy: 3.8276, AUC: 0.5335, F1: 0.0181\n",
      "\n",
      "Epoch 4 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:37<00:00, 12.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0112, Accuracy: 8.9655, AUC: 0.6508, F1: 0.0764\n",
      "Val   - Loss: 0.0035, Accuracy: 4.0690, AUC: 0.5697, F1: 0.0217\n",
      "Model improved by 0.000136: best model saved.\n",
      "\n",
      "Epoch 5 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0109, Accuracy: 12.0690, AUC: 0.7110, F1: 0.1073\n",
      "Val   - Loss: 0.0035, Accuracy: 5.7586, AUC: 0.6026, F1: 0.0422\n",
      "\n",
      "Epoch 6 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0106, Accuracy: 17.9310, AUC: 0.7624, F1: 0.1663\n",
      "Val   - Loss: 0.0034, Accuracy: 8.9655, AUC: 0.6401, F1: 0.0721\n",
      "Model improved by 0.000111: best model saved.\n",
      "\n",
      "Epoch 7 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0103, Accuracy: 24.1379, AUC: 0.8077, F1: 0.2248\n",
      "Val   - Loss: 0.0033, Accuracy: 11.4828, AUC: 0.6759, F1: 0.0918\n",
      "\n",
      "Epoch 8 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0100, Accuracy: 33.7931, AUC: 0.8442, F1: 0.3212\n",
      "Val   - Loss: 0.0033, Accuracy: 13.4483, AUC: 0.7080, F1: 0.1074\n",
      "Model improved by 0.000117: best model saved.\n",
      "\n",
      "Epoch 9 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0097, Accuracy: 40.6897, AUC: 0.8750, F1: 0.3843\n",
      "Val   - Loss: 0.0032, Accuracy: 15.6207, AUC: 0.7368, F1: 0.1286\n",
      "\n",
      "Epoch 10 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0094, Accuracy: 47.2414, AUC: 0.9016, F1: 0.4508\n",
      "Val   - Loss: 0.0032, Accuracy: 18.1034, AUC: 0.7616, F1: 0.1542\n",
      "Model improved by 0.000116: best model saved.\n",
      "\n",
      "Epoch 11 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0091, Accuracy: 53.4483, AUC: 0.9217, F1: 0.5139\n",
      "Val   - Loss: 0.0031, Accuracy: 20.7586, AUC: 0.7824, F1: 0.1854\n",
      "\n",
      "Epoch 12 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0088, Accuracy: 57.2414, AUC: 0.9385, F1: 0.5525\n",
      "Val   - Loss: 0.0031, Accuracy: 24.5172, AUC: 0.8001, F1: 0.2288\n",
      "Model improved by 0.000115: best model saved.\n",
      "\n",
      "Epoch 13 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0085, Accuracy: 61.3793, AUC: 0.9509, F1: 0.5916\n",
      "Val   - Loss: 0.0030, Accuracy: 27.1379, AUC: 0.8150, F1: 0.2606\n",
      "\n",
      "Epoch 14 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0083, Accuracy: 65.8621, AUC: 0.9608, F1: 0.6405\n",
      "Val   - Loss: 0.0029, Accuracy: 30.3448, AUC: 0.8276, F1: 0.2916\n",
      "Model improved by 0.000109: best model saved.\n",
      "\n",
      "Epoch 15 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0080, Accuracy: 68.6207, AUC: 0.9682, F1: 0.6715\n",
      "Val   - Loss: 0.0029, Accuracy: 32.8621, AUC: 0.8384, F1: 0.3170\n",
      "\n",
      "Epoch 16 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0077, Accuracy: 71.3793, AUC: 0.9734, F1: 0.7046\n",
      "Val   - Loss: 0.0028, Accuracy: 35.5862, AUC: 0.8477, F1: 0.3443\n",
      "Model improved by 0.000104: best model saved.\n",
      "\n",
      "Epoch 17 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0075, Accuracy: 72.4138, AUC: 0.9776, F1: 0.7172\n",
      "Val   - Loss: 0.0028, Accuracy: 38.3448, AUC: 0.8560, F1: 0.3741\n",
      "\n",
      "Epoch 18 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0072, Accuracy: 76.5517, AUC: 0.9808, F1: 0.7608\n",
      "Val   - Loss: 0.0027, Accuracy: 40.2069, AUC: 0.8631, F1: 0.3932\n",
      "\n",
      "Epoch 19 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:36<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0070, Accuracy: 78.6207, AUC: 0.9835, F1: 0.7827\n",
      "Val   - Loss: 0.0027, Accuracy: 42.2069, AUC: 0.8695, F1: 0.4158\n",
      "Model improved by 0.000147: best model saved.\n",
      "\n",
      "Epoch 20 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0067, Accuracy: 80.3448, AUC: 0.9856, F1: 0.8008\n",
      "Val   - Loss: 0.0027, Accuracy: 43.7241, AUC: 0.8752, F1: 0.4325\n",
      "\n",
      "Epoch 21 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0065, Accuracy: 82.0690, AUC: 0.9874, F1: 0.8179\n",
      "Val   - Loss: 0.0026, Accuracy: 45.0690, AUC: 0.8800, F1: 0.4490\n",
      "\n",
      "Epoch 22 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0063, Accuracy: 83.7931, AUC: 0.9888, F1: 0.8362\n",
      "Val   - Loss: 0.0026, Accuracy: 46.1724, AUC: 0.8843, F1: 0.4621\n",
      "Model improved by 0.000130: best model saved.\n",
      "\n",
      "Epoch 23 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0061, Accuracy: 84.8276, AUC: 0.9900, F1: 0.8469\n",
      "Val   - Loss: 0.0025, Accuracy: 46.7586, AUC: 0.8881, F1: 0.4697\n",
      "\n",
      "Epoch 24 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0059, Accuracy: 85.1724, AUC: 0.9914, F1: 0.8511\n",
      "Val   - Loss: 0.0025, Accuracy: 47.2414, AUC: 0.8915, F1: 0.4743\n",
      "\n",
      "Epoch 25 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0057, Accuracy: 86.8966, AUC: 0.9924, F1: 0.8695\n",
      "Val   - Loss: 0.0025, Accuracy: 48.1379, AUC: 0.8946, F1: 0.4841\n",
      "Model improved by 0.000114: best model saved.\n",
      "\n",
      "Epoch 26 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0055, Accuracy: 87.9310, AUC: 0.9931, F1: 0.8801\n",
      "Val   - Loss: 0.0024, Accuracy: 49.0000, AUC: 0.8976, F1: 0.4926\n",
      "\n",
      "Epoch 27 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0053, Accuracy: 88.2759, AUC: 0.9937, F1: 0.8837\n",
      "Val   - Loss: 0.0024, Accuracy: 49.3793, AUC: 0.9003, F1: 0.4955\n",
      "\n",
      "Epoch 28 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0051, Accuracy: 88.6207, AUC: 0.9945, F1: 0.8870\n",
      "Val   - Loss: 0.0024, Accuracy: 49.9655, AUC: 0.9029, F1: 0.5007\n",
      "Model improved by 0.000102: best model saved.\n",
      "\n",
      "Epoch 29 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0049, Accuracy: 89.6552, AUC: 0.9951, F1: 0.8964\n",
      "Val   - Loss: 0.0023, Accuracy: 50.5517, AUC: 0.9053, F1: 0.5056\n",
      "\n",
      "Epoch 30 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0047, Accuracy: 90.3448, AUC: 0.9957, F1: 0.9039\n",
      "Val   - Loss: 0.0023, Accuracy: 51.4483, AUC: 0.9075, F1: 0.5139\n",
      "\n",
      "Epoch 31 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0046, Accuracy: 91.0345, AUC: 0.9962, F1: 0.9113\n",
      "Val   - Loss: 0.0023, Accuracy: 51.7586, AUC: 0.9096, F1: 0.5165\n",
      "\n",
      "Epoch 32 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0044, Accuracy: 93.1034, AUC: 0.9966, F1: 0.9310\n",
      "Val   - Loss: 0.0022, Accuracy: 52.2069, AUC: 0.9116, F1: 0.5210\n",
      "Model improved by 0.000118: best model saved.\n",
      "\n",
      "Epoch 33 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0043, Accuracy: 93.4483, AUC: 0.9970, F1: 0.9345\n",
      "Val   - Loss: 0.0022, Accuracy: 52.5517, AUC: 0.9135, F1: 0.5250\n",
      "\n",
      "Epoch 34 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0041, Accuracy: 94.4828, AUC: 0.9974, F1: 0.9445\n",
      "Val   - Loss: 0.0022, Accuracy: 52.9310, AUC: 0.9152, F1: 0.5294\n",
      "\n",
      "Epoch 35 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0040, Accuracy: 95.1724, AUC: 0.9977, F1: 0.9516\n",
      "Val   - Loss: 0.0022, Accuracy: 53.2414, AUC: 0.9168, F1: 0.5331\n",
      "\n",
      "Epoch 36 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0038, Accuracy: 95.1724, AUC: 0.9981, F1: 0.9516\n",
      "Val   - Loss: 0.0021, Accuracy: 53.4138, AUC: 0.9183, F1: 0.5353\n",
      "Model improved by 0.000101: best model saved.\n",
      "\n",
      "Epoch 37 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0037, Accuracy: 95.5172, AUC: 0.9983, F1: 0.9550\n",
      "Val   - Loss: 0.0021, Accuracy: 54.0690, AUC: 0.9197, F1: 0.5422\n",
      "\n",
      "Epoch 38 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0036, Accuracy: 95.5172, AUC: 0.9986, F1: 0.9550\n",
      "Val   - Loss: 0.0021, Accuracy: 54.3448, AUC: 0.9211, F1: 0.5454\n",
      "\n",
      "Epoch 39 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0035, Accuracy: 95.5172, AUC: 0.9987, F1: 0.9550\n",
      "Val   - Loss: 0.0021, Accuracy: 54.8276, AUC: 0.9224, F1: 0.5503\n",
      "\n",
      "Epoch 40 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0034, Accuracy: 95.8621, AUC: 0.9989, F1: 0.9587\n",
      "Val   - Loss: 0.0020, Accuracy: 55.1724, AUC: 0.9237, F1: 0.5542\n",
      "\n",
      "Epoch 41 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0032, Accuracy: 95.8621, AUC: 0.9991, F1: 0.9587\n",
      "Val   - Loss: 0.0020, Accuracy: 55.6897, AUC: 0.9249, F1: 0.5598\n",
      "Model improved by 0.000109: best model saved.\n",
      "\n",
      "Epoch 42 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0031, Accuracy: 95.8621, AUC: 0.9992, F1: 0.9587\n",
      "Val   - Loss: 0.0020, Accuracy: 55.6897, AUC: 0.9260, F1: 0.5600\n",
      "\n",
      "Epoch 43 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0030, Accuracy: 96.5517, AUC: 0.9994, F1: 0.9656\n",
      "Val   - Loss: 0.0020, Accuracy: 55.7241, AUC: 0.9271, F1: 0.5601\n",
      "\n",
      "Epoch 44 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0029, Accuracy: 97.2414, AUC: 0.9994, F1: 0.9723\n",
      "Val   - Loss: 0.0020, Accuracy: 56.1724, AUC: 0.9282, F1: 0.5646\n",
      "\n",
      "Epoch 45 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:35<00:00, 11.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0028, Accuracy: 97.5862, AUC: 0.9995, F1: 0.9760\n",
      "Val   - Loss: 0.0020, Accuracy: 56.4138, AUC: 0.9291, F1: 0.5670\n",
      "\n",
      "Epoch 46 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:34<00:00, 11.62s/it]\n",
      "C:\\Users\\sovte\\AppData\\Local\\Temp\\ipykernel_34144\\1473212738.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('ASL/output/best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0027, Accuracy: 97.9310, AUC: 0.9996, F1: 0.9794\n",
      "Val   - Loss: 0.0019, Accuracy: 56.6552, AUC: 0.9301, F1: 0.5696\n",
      "No significant improvement for 5 epochs. Early stopping triggered.\n",
      "\n",
      "Training complete in 29.98 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 3/3 [00:35<00:00, 11.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ResNet model saved\n",
      "\n",
      "Training CNN model...\n",
      "\n",
      "Epoch 1 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:21<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0119, Accuracy: 3.4483, AUC: 0.5138, F1: 0.0049\n",
      "Val   - Loss: 0.0036, Accuracy: 3.4483, AUC: 0.5032, F1: 0.0023\n",
      "Model improved by inf: best model saved.\n",
      "\n",
      "Epoch 2 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:22<00:00,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0119, Accuracy: 3.4483, AUC: 0.5031, F1: 0.0023\n",
      "Val   - Loss: 0.0035, Accuracy: 3.6897, AUC: 0.5341, F1: 0.0053\n",
      "\n",
      "Epoch 3 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:22<00:00,  7.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0117, Accuracy: 3.4483, AUC: 0.5496, F1: 0.0024\n",
      "Val   - Loss: 0.0035, Accuracy: 3.4483, AUC: 0.5460, F1: 0.0023\n",
      "\n",
      "Epoch 4 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:22<00:00,  7.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0116, Accuracy: 3.4483, AUC: 0.5827, F1: 0.0023\n",
      "Val   - Loss: 0.0035, Accuracy: 5.4138, AUC: 0.5597, F1: 0.0161\n",
      "\n",
      "Epoch 5 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:21<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0116, Accuracy: 6.8966, AUC: 0.6122, F1: 0.0188\n",
      "Val   - Loss: 0.0035, Accuracy: 3.9310, AUC: 0.5668, F1: 0.0043\n",
      "\n",
      "Epoch 6 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "Validating: 100%|██████████| 3/3 [00:22<00:00,  7.36s/it]\n",
      "C:\\Users\\sovte\\AppData\\Local\\Temp\\ipykernel_34144\\1473212738.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('ASL/output/best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0116, Accuracy: 3.4483, AUC: 0.6346, F1: 0.0030\n",
      "Val   - Loss: 0.0035, Accuracy: 3.4483, AUC: 0.5677, F1: 0.0024\n",
      "No significant improvement for 5 epochs. Early stopping triggered.\n",
      "\n",
      "Training complete in 2.58 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 3/3 [00:21<00:00,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CNN model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cnn_models import CustomCNN\n",
    "from resnet_models import ResnetModel\n",
    "\n",
    "# Initialize models\n",
    "models_dict = {\n",
    "    'ResNet': ResnetModel().to(device),\n",
    "    'CNN': CustomCNN().to(device)\n",
    "}\n",
    "\n",
    "# Train each model\n",
    "results = {}\n",
    "for model_name, model in models_dict.items():\n",
    "    print(f\"\\nTraining {model_name} model...\")\n",
    "    \n",
    "    # Initialize optimizer and criterion\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = CNNTrainer(model, device, criterion, optimizer, patience=5)\n",
    "    \n",
    "    # Train the model\n",
    "    best_model, train_loss, train_accuracy, val_loss, val_accuracy, train_time = trainer.train(trainloader, valloader, num_epoch)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_accuracy, test_auc, test_f1, fps = trainer.evaluate(testloader)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'model': best_model,\n",
    "        'train_loss': train_loss,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_auc': test_auc,\n",
    "        'test_f1': test_f1,\n",
    "        'fps': fps,\n",
    "        'train_time': train_time\n",
    "    }\n",
    "    \n",
    "    # Save the best model\n",
    "    torch.save(best_model.state_dict(), f'ASL/output/best_{model_name.lower()}_model.pth')\n",
    "    print(f\"Best {model_name} model saved\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results saved to ASL/output/training_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame and save as Excel\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'Model'})\n",
    "\n",
    "# Save to Excel\n",
    "results_df.to_excel('ASL/output/training_results.xlsx', index=False)\n",
    "print(\"Training results saved to ASL/output/training_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process all images\n",
    "# fig, axes = plt.subplots((len(all_files) + 4) // 5, 5, figsize=(20, 4*((len(all_files) + 4) // 5)))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i, img_file in enumerate(all_files):\n",
    "#     # Load and process image\n",
    "#     test_img = os.path.join(test_dir, img_file)\n",
    "#     image = cv2.imread(test_img)\n",
    "#     image_copy = image.copy()\n",
    "    \n",
    "#     # Preprocess image\n",
    "#     image = aug(image=np.array(image))['image']\n",
    "#     image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "#     image = torch.tensor(image, dtype=torch.float)\n",
    "#     image = image.unsqueeze(0)\n",
    "    \n",
    "#     # Make prediction\n",
    "#     start = time.time()\n",
    "#     outputs = model(image)\n",
    "#     _, preds = torch.max(outputs.data, 1)\n",
    "#     end = time.time()\n",
    "    \n",
    "#     # Add prediction to image\n",
    "#     cv2.putText(image_copy, lb.classes_[preds], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "    \n",
    "#     # Display in subplot\n",
    "#     axes[i].imshow(cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB))\n",
    "#     axes[i].axis('off')\n",
    "#     axes[i].set_title(f\"{lb.classes_[preds]}\\n({(end-start):.3f}s)\")\n",
    "\n",
    "# # Hide any empty subplots\n",
    "# for j in range(i+1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time capture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
